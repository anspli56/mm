import os
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"  # –û—Ç–∫–ª—é—á–∞–µ–º oneDNN –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π TensorFlow

from collections import deque, OrderedDict
import json
import logging
import hashlib
import customtkinter as ctk
import tkinter as tk
from tkinter import messagebox
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import MiniBatchKMeans
from sklearn.metrics.pairwise import cosine_similarity
import uuid
import pygame
from pygame import mixer
import time
import threading
import ast
from typing import Dict, Any, List, Tuple, Optional
import re
from bs4 import BeautifulSoup
from docx import Document
import openpyxl
from tinydb import TinyDB, Query
import joblib
from cryptography.fernet import Fernet
import black
import requests
import importlib.util
import sys
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
import random
import base64
from gtts import gTTS  # –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç gTTS

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# –ò–º–ø–æ—Ä—Ç—ã TensorFlow
try:
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense
    from tensorflow.keras.optimizers import Adam, SGD
except ImportError as e:
    logging.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ tensorflow.keras: {e}")
    print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ TensorFlow: 'pip install tensorflow'")

# –ò–º–ø–æ—Ä—Ç—ã Fast.ai
try:
    from fastai.text.all import *
    from fastai.text.models import AWD_LSTM
except ImportError as e:
    logging.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ fastai: {e}")
    print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Fast.ai: 'pip install fastai'")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("nere_more.log"), logging.StreamHandler()],
)

ctk.set_appearance_mode("dark")
ctk.set_default_color_theme("dark-blue")

# –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —Å Fast.ai (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)
class FastAITextAnalyzer:
    def __init__(self, csv_path="sentiment_data.csv"):
        self.csv_path = csv_path
        self.dls = None
        self.learn = None
        self._load_or_train_model()

    def _load_or_train_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ –æ–±—É—á–∞–µ–º —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å Fast.ai —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""
        try:
            if os.path.exists("text_regressor.pth"):
                self.learn = load_learner("text_regressor.pth")
                logging.info("–ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Fast.ai")
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤
                if os.path.exists(self.csv_path):
                    data = pd.read_csv(self.csv_path)
                    if 'text' not in data.columns or 'score' not in data.columns:
                        raise ValueError("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'text' –∏ 'score' (–æ—Ç -1 –¥–æ 1)")
                else:
                    # –ù–µ–±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –æ—Ç–∑—ã–≤–∞–º–∏ –∏ —á–∏—Å–ª–æ–≤—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏
                    data = pd.DataFrame({
                        'text': [
                            "–û—Ç–ª–∏—á–Ω—ã–π —Å–µ—Ä–≤–∏—Å, —è –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ!",
                            "–£–∂–∞—Å–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≤–µ—Ä–Ω—É—Å—å",
                            "–í—Å—ë –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ",
                            "–û—á–µ–Ω—å –≥—Ä—É—Å—Ç–Ω–æ –æ—Ç —Ç–∞–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞",
                            "–ó–ª—é—Å—å –Ω–∞ –≤–∞—à—É –¥–æ—Å—Ç–∞–≤–∫—É, —ç—Ç–æ –∫–æ—à–º–∞—Ä",
                            "–ü—Ä–µ–∫—Ä–∞—Å–Ω—ã–π –¥–µ–Ω—å –±–ª–∞–≥–æ–¥–∞—Ä—è –≤–∞–º",
                            "–¢–∞–∫ —Å–µ–±–µ, –º–æ–≥–ª–æ –±—ã—Ç—å –ª—É—á—à–µ",
                            "–ü—Ä–æ—Å—Ç–æ –æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ",
                            "–°—É–ø–µ—Ä, –≤—Å—ë –∏–¥–µ–∞–ª—å–Ω–æ!",
                            "–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω, –æ–∂–∏–¥–∞–ª –±–æ–ª—å—à–µ–≥–æ"
                        ],
                        'score': [1.0, -1.0, 0.0, -0.6, -0.9, 0.8, -0.2, -0.8, 1.0, -0.4]
                    })
                    data.to_csv(self.csv_path, index=False)
                    logging.warning(f"–°–æ–∑–¥–∞–Ω –ø—Ä–∏–º–µ—Ä–Ω—ã–π —Ñ–∞–π–ª {self.csv_path}. –ó–∞–º–µ–Ω–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ.")

                # –°–æ–∑–¥–∞–µ–º DataLoaders –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
                dls = TextDataLoaders.from_df(
                    data,
                    text_col='text',
                    label_col='score',
                    valid_pct=0.2,
                    text_vocab=None,
                    is_lm=False
                )

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                self.learn = text_learner(
                    dls,
                    AWD_LSTM,
                    drop_mult=0.5,
                    metrics=[mae],  # –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
                    loss_func=MSELossFlat()  # –°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
                )

                # –î–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                self.learn.fit_one_cycle(3, 1e-2)
                self.learn.export("text_regressor.pth")
                logging.info("–°–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–æ–≤–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Fast.ai")
            self.dls = self.learn.dls
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Fast.ai –º–æ–¥–µ–ª–∏: {e}")
            self.learn = None

    def predict_sentiment_score(self, text: str) -> float:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —á–∏—Å–ª–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç -1 –¥–æ 1."""
        if not self.learn:
            return 0.0
        try:
            pred = self.learn.predict(text)[0].item()  # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            return float(pred)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Fast.ai: {e}")
            return 0.0

    def fine_tune(self, text: str, score: float):
        """–î–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤–æ–º –ø—Ä–∏–º–µ—Ä–µ."""
        if not self.learn:
            return
        try:
            df = pd.DataFrame({'text': [text], 'score': [score]})
            dls = TextDataLoaders.from_df(df, text_col='text', label_col='score', valid_pct=0)
            self.learn.dls = dls
            self.learn.fine_tune(1, base_lr=1e-3)
            self.learn.export("text_regressor.pth")
            logging.info(f"–ú–æ–¥–µ–ª—å Fast.ai –¥–æ–æ–±—É—á–µ–Ω–∞ –Ω–∞: {text} -> {score:.2f}")
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV
            with open(self.csv_path, 'a', encoding='utf-8') as f:
                f.write(f'"{text}",{score}\n')
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è Fast.ai: {e}")

class CodeEditorWindow(ctk.CTkToplevel):
    def __init__(self, parent, services):
        super().__init__(parent)
        self.title("–†–µ–¥–∞–∫—Ç–æ—Ä –∫–æ–¥–∞")
        self.geometry("600x400")
        self.services = services
        self._init_ui()

    def _init_ui(self):
        self.code_textbox = ctk.CTkTextbox(self, width=580, height=300, fg_color="#2F3536", text_color="#FFFFFF")
        self.code_textbox.pack(padx=10, pady=10)
        ctk.CTkButton(self, text="–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", command=self._analyze_code).pack(pady=5)

    def _analyze_code(self):
        code = self.code_textbox.get("1.0", "end-1c").strip()
        if code:
            purpose, location = self.services.code_optimizer.classify_code(code)
            self.code_textbox.delete("1.0", "end")
            self.code_textbox.insert("1.0", f"–ö–æ–¥:\n{code}\n\n–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:\n- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {purpose}\n- –ú–µ—Å—Ç–æ: {location}")

def validate_folder_id(folder_id: str) -> bool:
    return bool(re.match(r'^[a-zA-Z0-9]{20}$', folder_id))

def fibonacci(n: int) -> int:
    if n <= 1:
        return n
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b

class AudioManager:
    def play_sound(self, text: str, filename: str) -> None:
        try:
            tts = gTTS(text, lang="ru")
            tts.save(filename)
            pygame.mixer.init()
            pygame.mixer.music.load(filename)
            pygame.mixer.music.play()
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
            pygame.mixer.music.stop()
            pygame.mixer.quit()
            if os.path.exists(filename):
                os.remove(filename)
        except (pygame.error, OSError) as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")

class Config:
    _instance = None
    _lock = threading.Lock()
    _cipher_key = Fernet.generate_key()
    _cipher = Fernet(_cipher_key)

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._load_config()
                cls._instance._validate_and_update_on_startup()
            return cls._instance

    def _load_config(self):
        self.default_config = {
            "database": "nere_more_knowledge.json",
            "yandex": {
                "keys": [{"id": "gpt_key_1", "value": "", "type": "gpt"}],
                "folder_id": ""
            },
            "ui": {"animation_speed": 0.05, "max_context": 10, "audio_enabled": True},
            "learning": {"cluster_size": 5, "feedback_weight": 0.9, "learning_rate": 0.0},
            "code_classification": {
                "purposes": ["algorithm", "UI", "data_processing", "network", "utility"],
                "locations": ["core", "GUI", "services", "knowledge"],
                "keywords": {
                    "algorithm": ["def", "for", "while", "if"],
                    "UI": ["tkinter", "ctk", "label", "button"],
                    "data_processing": ["numpy", "sklearn", "pandas"],
                    "network": ["requests", "socket"],
                    "utility": ["os", "logging", "time"]
                }
            }
        }
        config_file = "nere_more_config.json"
        try:
            if os.path.exists(config_file):
                with open(config_file, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if not content:
                        self.config = self.default_config
                        self._save_config()
                        return
                    self.config = json.loads(content)
                    temp_config = self.default_config.copy()
                    temp_config.update(self.config)
                    self.config = temp_config
            else:
                self.config = self.default_config
                self._save_config()
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            self.config = self.default_config
            self._save_config()

    def _save_config(self):
        try:
            with open("nere_more_config.json", "w", encoding="utf-8") as f:
                json.dump(self.config, f, indent=4)
        except IOError as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

    def _validate_and_update_on_startup(self):
        api_key = self.get_key()
        folder_id = self.get_folder_id()
        
        if not api_key or not folder_id:
            logging.info("API –∫–ª—é—á –∏–ª–∏ folder_id –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            self.update_api_key("gpt_key_1", "AQVNzHvgRbhMqf98hCeuO8ek88XTmHFnVJ3fKcmo")
            self.update_folder_id("b1g170pkl3ihbn8bc3kd")
            return
            
        temp_gpt = YandexGPT(api_key, folder_id)
        available, status = temp_gpt.check_availability()
        
        if not available:
            logging.warning(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã: {status}. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            self.update_api_key("gpt_key_1", "AQVNzHvgRbhMqf98hCeuO8ek88XTmHFnVJ3fKcmo")
            self.update_folder_id("b1g170pkl3ihbn8bc3kd")

    @property
    def data(self) -> Dict[str, Any]:
        return self.config

    def get_key(self) -> str:
        for key in self.config["yandex"]["keys"]:
            if key["type"] == "gpt":
                try:
                    return self._cipher.decrypt(key["value"].encode()).decode()
                except Exception:
                    return key["value"]
        return ""

    def update_api_key(self, key_id: str, value: str) -> bool:
        temp_gpt = YandexGPT(value, self.get_folder_id())
        available, status = temp_gpt.check_availability()
        
        if not available:
            logging.error(f"–ù–æ–≤—ã–π API –∫–ª—é—á –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω: {status}")
            return False
            
        encrypted_value = self._cipher.encrypt(value.encode()).decode()
        for key in self.config["yandex"]["keys"]:
            if key["id"] == key_id:
                key["value"] = encrypted_value
                self._save_config()
                return True
        self.config["yandex"]["keys"].append({"id": key_id, "value": encrypted_value, "type": "gpt"})
        self._save_config()
        return True

    def get_folder_id(self) -> str:
        return self.config["yandex"].get("folder_id", "")

    def update_folder_id(self, folder_id: str) -> bool:
        if not validate_folder_id(folder_id):
            logging.error("–ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π folder_id")
            return False
            
        api_key = self.get_key()
        if api_key:
            temp_gpt = YandexGPT(api_key, folder_id)
            available, status = temp_gpt.check_availability()
            if not available:
                logging.error(f"folder_id –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω —Å —Ç–µ–∫—É—â–∏–º –∫–ª—é—á–æ–º: {status}")
                return False
                
        self.config["yandex"]["folder_id"] = folder_id
        self._save_config()
        return True

class CodeOptimizationModule:
    def __init__(self, config: Config):
        self.config = config.data["code_classification"]

    def classify_code(self, code: str) -> Tuple[str, str]:
        purpose_score = {p: 0 for p in self.config["purposes"]}
        tokens = re.findall(r'\w+', code.lower())
        
        for purpose, keywords in self.config["keywords"].items():
            for keyword in keywords:
                if keyword in tokens:
                    purpose_score[purpose] += 1
        
        purpose = max(purpose_score, key=purpose_score.get, default="utility")
        
        if "ctk" in code or "tkinter" in code:
            location = "GUI"
        elif "requests" in code or "socket" in code:
            location = "services"
        elif "numpy" in code or "sklearn" in code:
            location = "knowledge"
        else:
            location = "core"
        
        return purpose, location

    def detect_errors(self, code: str) -> List[str]:
        errors = []
        try:
            ast.parse(code)
        except SyntaxError as e:
            errors.append(f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        return errors if errors else ["–û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"]

    def analyze_structure(self, code: str) -> Dict[str, List[str]]:
        tree = ast.parse(code)
        structure = {"functions": [], "classes": []}
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                structure["functions"].append(node.name)
            elif isinstance(node, ast.ClassDef):
                structure["classes"].append(node.name)
        
        return structure

    def suggest_structure(self, code: str, errors: List[str]) -> str:
        suggestions = []
        try:
            tree = ast.parse(code, mode='exec', type_comments=True)
        except:
            suggestions.append("–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")
            return "\n".join(suggestions)
        
        for error in errors:
            if "syntax" in error.lower():
                suggestions.append("–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–∫–æ–±–∫–∏, –æ—Ç—Å—Ç—É–ø—ã).")
        
        return "\n".join(suggestions) if suggestions else "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞."

    def duplicate_structure(self, code: str) -> str:
        tree = ast.parse(code)
        duplicated_code = []
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                duplicated_code.append(ast.unparse(node))
        
        return "\n\n".join(duplicated_code) if duplicated_code else code

    def suggest_integration_points(self, code: str, location: str) -> List[Tuple[str, str]]:
        integration_points = []
        tree = ast.parse(code)
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                integration_points.append((node.name, f"–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ {node.name} –≤ {location}"))
            elif isinstance(node, ast.ClassDef):
                integration_points.append((node.name, f"–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞ {node.name} –≤ {location}"))
        
        return integration_points

class YandexGPT:
    def __init__(self, api_key: str, folder_id: str):
        self.api_key = api_key
        self.folder_id = folder_id
        self.url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        self.model = "yandexgpt-lite"
        self.temperature = 0.6
        self.max_tokens = 2000
        self.available = False
        self.status = "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ"
        self._validate_credentials()

    def _validate_credentials(self):
        if not self.api_key or len(self.api_key.strip()) < 10:
            self.status = "–û—à–∏–±–∫–∞: API-–∫–ª—é—á –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π"
            return
        if not validate_folder_id(self.folder_id):
            self.status = "–û—à–∏–±–∫–∞: folder_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 20 —Å–∏–º–≤–æ–ª–æ–≤ (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã)"
            return
        self.check_availability()

    def check_availability(self) -> Tuple[bool, str]:
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Api-Key {self.api_key}"
            }
            payload = {
                "modelUri": f"gpt://{self.folder_id}/{self.model}",
                "completionOptions": {
                    "maxTokens": self.max_tokens,
                    "temperature": self.temperature
                },
                "messages": [{"role": "user", "text": "Test"}]
            }
            response = requests.post(self.url, headers=headers, json=payload)
            self.available = response.status_code == 200
            self.status = "–î–æ—Å—Ç—É–ø–Ω–æ" if self.available else f"–û—à–∏–±–∫–∞: {response.status_code}"
            return self.available, self.status
        except Exception as e:
            self.available = False
            self.status = f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {str(e)}"
            return self.available, self.status

    def invoke(self, json_payload: Dict[str, Any]) -> str:
        if not self.available:
            return f"API –æ—Ç–∫–ª—é—á–µ–Ω: {self.status}"
        
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Api-Key {self.api_key}"
            }
            response = requests.post(self.url, headers=headers, json=json_payload)
            response.raise_for_status()
            result = response.json()
            return result.get("result", {}).get("alternatives", [{}])[0].get("message", {}).get("text", "No data")
        except requests.RequestException as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Yandex GPT: {e}")
            return f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {str(e)}"

class KnowledgeBase:
    def __init__(self, services: 'YandexAIServices'):
        self.config = Config().data
        self.services = services
        self.db = TinyDB(self.config["database"])
        self.vectorizer = TfidfVectorizer(max_features=10000)
        self.kmeans: Optional[MiniBatchKMeans] = None
        self._lock = threading.Lock()
        self.embeddings_cache = OrderedDict(maxlen=1000)
        self.query_cache = OrderedDict(maxlen=1000)
        self.vectorizer_fitted = False
        self.experience_level = 0
        self.learning_rate = 0.0
        self.context_history = deque(maxlen=50)
        self._load_state()

    def _load_state(self):
        try:
            if os.path.exists("vectorizer.pkl") and os.path.exists("kmeans.pkl"):
                self.vectorizer = joblib.load("vectorizer.pkl")
                self.kmeans = joblib.load("kmeans.pkl")
                self.vectorizer_fitted = True
            else:
                docs = [entry['response'] for entry in self.db.all() if 'response' in entry]
                if docs:
                    self.vectorizer.fit(docs)
                    self.vectorizer_fitted = True
                    n_samples = len(docs)
                    n_clusters = min(self.config["learning"]["cluster_size"], n_samples)
                    self.kmeans = MiniBatchKMeans(n_clusters=n_clusters)
                    embeddings = []
                    for entry in self.db.all():
                        if 'embeddings' in entry:
                            embeddings_bytes = base64.b64decode(entry['embeddings'])
                            embeddings.append(np.frombuffer(embeddings_bytes, dtype=np.float16))
                    if embeddings:
                        self.kmeans.fit(np.stack(embeddings))
                    self._save_state()
            self.experience_level = len(self.db.all())
            self.learning_rate = self.config["learning"]["learning_rate"]
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
            self.vectorizer_fitted = False

    def _save_state(self):
        if self.vectorizer_fitted:
            try:
                joblib.dump(self.vectorizer, "vectorizer.pkl")
                joblib.dump(self.kmeans, "kmeans.pkl")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")

    def _ensure_vectorizer_fitted(self, text: str):
        if not self.vectorizer_fitted:
            docs = [entry['response'] for entry in self.db.all() if 'response' in entry]
            if not docs:
                docs = [text]
            self.vectorizer.fit(docs)
            self.vectorizer_fitted = True
            n_clusters = min(self.config["learning"]["cluster_size"], len(docs))
            self.kmeans = MiniBatchKMeans(n_clusters=n_clusters)
            self._save_state()

    def update_experience(self) -> float:
        self.experience_level += 1
        fib_value = fibonacci(min(self.experience_level, 20))
        self.learning_rate = min(100.0, fib_value * 0.5)
        self.config["learning"]["learning_rate"] = self.learning_rate
        Config()._save_config()
        return self.learning_rate

    def save(self, query: str, response: str, context: str = "", feedback: float = 0.0):
        with self._lock:
            if len(response.strip()) < 5:
                return
            query_hash = hashlib.md5(query.encode()).hexdigest()
            self.query_cache[query_hash] = response
            self._ensure_vectorizer_fitted(response)
            query_vec = self.vectorizer.transform([query]).toarray().astype(np.float16)[0]
            embeddings = self.vectorizer.transform([response]).toarray().astype(np.float16)[0]
            embeddings_base64 = base64.b64encode(embeddings.tobytes()).decode('utf-8')
            entry = {
                'id': str(uuid.uuid4()),
                'query': query,
                'response': response,
                'context': context,
                'embeddings': embeddings_base64,
                'feedback': feedback,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'learning_rate': self.update_experience()
            }
            self.db.insert(entry)
            self.context_history.append(f"–í–æ–ø—Ä–æ—Å: {query}\n–û—Ç–≤–µ—Ç: {response}")

    def get_similar(self, query: str, top_n: int = 5) -> List[Tuple[str, str, float]]:
        self._ensure_vectorizer_fitted(query)
        query_vec = self.vectorizer.transform([query]).toarray().astype(np.float16)[0]
        all_data = []
        for entry in self.db.all():
            if 'embeddings' in entry:
                embeddings_bytes = base64.b64decode(entry['embeddings'])
                embeddings_array = np.frombuffer(embeddings_bytes, dtype=np.float16)
                all_data.append((entry['query'], entry['response'], embeddings_array))
        if not all_data:
            return []
        embeddings = np.stack([item[2] for item in all_data])
        similarities = cosine_similarity(query_vec.reshape(1, -1), embeddings)[0]
        results = sorted(zip(all_data, similarities), key=lambda x: x[1], reverse=True)[:top_n]
        return [(q, r, float(s)) for (q, r, _), s in results]

    def save_web_content(self, url: str, query: str) -> bool:
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text(separator=' ', strip=True)
            if text:
                self.save(query, text, context=f"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å —Å–∞–π—Ç–∞: {url}")
                return True
            return False
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å {url}: {e}")
            return False

    def build_context(self, query: str) -> str:
        similar = self.get_similar(query, top_n=3)
        context = "\n\n".join([f"–†–∞–Ω–µ–µ: {q}\n–û—Ç–≤–µ—Ç: {r} (—Å—Ö–æ–¥—Å—Ç–≤–æ: {s:.2f})" for q, r, s in similar])
        if not context:
            context = "–£ –º–µ–Ω—è –ø–æ–∫–∞ –º–∞–ª–æ –æ–ø—ã—Ç–∞ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –Ω–æ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
        history = "\n".join(list(self.context_history)[-5:])
        return f"–ò—Å—Ç–æ—Ä–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è:\n{history}\n\n–ü—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç:\n{context}"

    def _clear_cache(self, text_id: str = None):
        with self._lock:
            if text_id:
                self.db.remove(Query().query.matches(f".*ID: {text_id}.*"))
            else:
                self.db.truncate()
                self.embeddings_cache.clear()
                self.query_cache.clear()
                self.context_history.clear()
                self.vectorizer_fitted = False
                self.kmeans = None
                self.experience_level = 0
                self.learning_rate = 0.0
            self._save_state()

class DataModelTrainer:
    def __init__(self):
        self.model = None
        self.history = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        logging.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataModelTrainer")

    def generate_synthetic_data(self, n_samples=1000):
        X, y = make_classification(n_samples=n_samples, n_features=20, n_classes=2, random_state=42)
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        logging.info("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")

    def build_model(self, optimizer_name="Adam", learning_rate=0.001):
        self.model = Sequential([
            Dense(64, activation='relu', input_shape=(self.X_train.shape[1],)),
            Dense(32, activation='relu'),
            Dense(1, activation='sigmoid')
        ])
        
        if optimizer_name == "Adam":
            optimizer = Adam(learning_rate=learning_rate)
        else:
            optimizer = SGD(learning_rate=learning_rate)
        
        self.model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
        logging.info(f"–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º {optimizer_name} –∏ learning_rate={learning_rate}")

    def train_model(self, epochs=50, batch_size=32):
        if self.model is None or self.X_train is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
        self.history = self.model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size,
                                      validation_data=(self.X_test, self.y_test), verbose=1)
        logging.info(f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: {epochs} —ç–ø–æ—Ö, —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ {batch_size}")

    def visualize_results(self, output_path="training_results.png"):
        if self.history is None:
            logging.error("–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            return

        history_df = pd.DataFrame(self.history.history)
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        sns.lineplot(data=history_df[['loss', 'val_loss']])
        plt.title('Loss over Epochs')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')

        plt.subplot(1, 2, 2)
        sns.lineplot(data=history_df[['accuracy', 'val_accuracy']])
        plt.title('Accuracy over Epochs')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')

        plt.tight_layout()
        plt.savefig(output_path)
        plt.close()
        logging.info(f"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")

class InteractiveBehavior:
    def __init__(self, gui_interface):
        self.gui = gui_interface
        self.last_interaction = time.time()
        self.user_mood = 0.0
        self.greetings = ["–ü—Ä–∏–≤–µ—Ç!", "–ó–¥–æ—Ä–æ–≤–æ!", "–ö–∞–∫ –¥–µ–ª–∞?"]
        self.questions = ["–ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?", "–ü–æ—á–µ–º—É –º–æ–ª—á–∏—à—å?", "–ö–∞–∫ —É –≤–∞—Å –¥–µ–ª–∞?", "–ß—Ç–æ –Ω–æ–≤–æ–≥–æ?"]
        self.suggestions = [
            "–ú–æ–∂–µ—Ç, –æ–±—É—á–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö?",
            "–î–∞–≤–∞–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∫–æ–π-–Ω–∏–±—É–¥—å –∫–æ–¥?",
            "–•–æ—á–µ—à—å —É–∑–Ω–∞—Ç—å —á—Ç–æ-—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ?",
            "–ö–∞–∫ –Ω–∞—Å—á–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö?"
        ]
        self.is_running = False
        self.thread = None
        self.text_analyzer = FastAITextAnalyzer()

    def start(self):
        self.is_running = True
        self.thread = threading.Thread(target=self._interaction_loop, daemon=True)
        self.thread.start()

    def stop(self):
        self.is_running = False
        if self.thread:
            self.thread.join()

    def _interaction_loop(self):
        while self.is_running:
            time_since_last = time.time() - self.last_interaction
            if time_since_last > 30:
                self._interact_with_user()
                self.last_interaction = time.time()
            time.sleep(5)

    def _interact_with_user(self):
        last_input = self.gui.input_entry.get().strip()
        if last_input:
            score = self.text_analyzer.predict_sentiment_score(last_input)
            self.user_mood = score
            logging.info(f"Fast.ai –∞–Ω–∞–ª–∏–∑: {last_input} -> –æ—Ü–µ–Ω–∫–∞: {score:.2f}")
            self.text_analyzer.fine_tune(last_input, score)

        if time.time() - self.last_interaction > 60:
            question = random.choice(self.questions)
            self.gui.display_response(question)
        else:
            if self.user_mood > 0.5:
                greeting = random.choice(self.greetings) + " –¢—ã –≤—ã–≥–ª—è–¥–∏—à—å —Å—á–∞—Å—Ç–ª–∏–≤—ã–º!"
            elif self.user_mood < -0.5:
                greeting = random.choice(self.greetings) + " –ù–µ –≥—Ä—É—Å—Ç–∏, –¥–∞–≤–∞–π —á—Ç–æ-–Ω–∏–±—É–¥—å —Å–¥–µ–ª–∞–µ–º!"
            else:
                greeting = random.choice(self.greetings)
            suggestion = random.choice(self.suggestions)
            self.gui.display_response(f"{greeting}\n{suggestion}")

    def update_last_interaction(self):
        self.last_interaction = time.time()

class YandexAIServices:
    def __init__(self, gui_parent=None):
        self.config = Config()
        self.gui_parent = gui_parent
        self._request_credentials_if_needed()
        self.knowledge = KnowledgeBase(self)
        self.gpt = YandexGPT(self.config.get_key(), self.config.get_folder_id())
        self.code_optimizer = CodeOptimizationModule(self.config)
        self.data_trainer = DataModelTrainer()
        self.text_analyzer = FastAITextAnalyzer()
        
        available, status = self.gpt.check_availability()
        if not available:
            logging.warning(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π API: {status}")
            if gui_parent:
                gui_parent.status_label.configure(text=f"–û—à–∏–±–∫–∞ API: {status}")

    def _request_credentials_if_needed(self):
        if not validate_folder_id(self.config.get_folder_id()):
            folder_id = ctk.CTkInputDialog(text="–í–≤–µ–¥–∏—Ç–µ folder_id (20 —Å–∏–º–≤–æ–ª–æ–≤):", title="Folder ID").get_input()
            if folder_id and self.config.update_folder_id(folder_id):
                logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω folder_id: {folder_id}")
        if not self.config.get_key():
            api_key = ctk.CTkInputDialog(text="–í–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á:", title="API Key").get_input()
            if api_key and self.config.update_api_key("gpt_key_1", api_key):
                logging.info("API –∫–ª—é—á –æ–±–Ω–æ–≤–ª–µ–Ω")

    def check_api_key(self) -> Tuple[bool, str]:
        return self.gpt.check_availability()

    def train_and_visualize(self, epochs=50, batch_size=32, optimizer_name="Adam", learning_rate=0.001):
        try:
            self.data_trainer.generate_synthetic_data()
            self.data_trainer.build_model(optimizer_name=optimizer_name, learning_rate=learning_rate)
            self.data_trainer.train_model(epochs=epochs, batch_size=batch_size)
            self.data_trainer.visualize_results()
            return f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞! –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ training_results.png\n–û–ø—ã—Ç –ò–ò: {self.knowledge.learning_rate:.1f}%"
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {str(e)}"

    def suggest_action_algorithm(self, query: str, user_emotion: Optional[float] = None) -> str:
        if user_emotion is None:
            user_emotion = self.text_analyzer.predict_sentiment_score(query)
            logging.info(f"Fast.ai –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {query} -> –æ—Ü–µ–Ω–∫–∞: {user_emotion:.2f}")
            self.text_analyzer.fine_tune(query, user_emotion)

        keywords = re.findall(r'\w+', query.lower())
        main_focus = max(keywords, key=lambda w: len(w), default="–∑–∞–ø—Ä–æ—Å")

        similar_entries = self.knowledge.get_similar(query, top_n=5)
        memory_context = "\n".join([f"[{s:.2f}] {r}" for _, r, s in similar_entries]) if similar_entries else "–ù–µ—Ç —Å—Ö–æ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö"

        if user_emotion > 0.5:
            tone = "—Ä–∞–¥–æ—Å—Ç–Ω—ã–π"
            suggestion = "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ, —è —Å —Ä–∞–¥–æ—Å—Ç—å—é –ø–æ–º–æ–≥—É!"
        elif user_emotion < -0.5:
            tone = "–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π"
            suggestion = "–ù–µ –ø–µ—Ä–µ–∂–∏–≤–∞–π—Ç–µ, —è –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å!"
        else:
            tone = "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π"
            suggestion = "–î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –≤–∞—à –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–µ."

        built_context = self.knowledge.build_context(query)
        prompt = {
            "modelUri": f"gpt://{self.config.get_folder_id()}/{self.gpt.model}",
            "completionOptions": {
                "stream": False,
                "temperature": 0.5,
                "maxTokens": 2000
            },
            "messages": [
                {
                    "role": "system",
                    "text": f"–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å —É—Ä–æ–≤–Ω–µ–º –æ–ø—ã—Ç–∞ {self.knowledge.learning_rate:.1f}%. –ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–π—Å—è –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ç–æ–Ω: {tone})."
                },
                {
                    "role": "user",
                    "text": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{memory_context}\n\n–ó–∞–ø—Ä–æ—Å: {query}\n\n–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–∫—É—Å: {main_focus}"
                }
            ]
        }
        response = self.gpt.invoke(prompt)
        resp_score = self.text_analyzer.predict_sentiment_score(response)
        logging.info(f"Fast.ai –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞: {response[:50]}... -> –æ—Ü–µ–Ω–∫–∞: {resp_score:.2f}")
        self.knowledge.save(query, response, context=f"–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω: {tone}, –§–æ–∫—É—Å: {main_focus}")
        return (
            f"–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–∫—É—Å: {main_focus}\n"
            f"–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω: {tone}\n"
            f"–û—Ü–µ–Ω–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {user_emotion:.2f}\n"
            f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {suggestion}\n"
            f"–û—Ç–≤–µ—Ç: {response}\n"
            f"–û—Ü–µ–Ω–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: {resp_score:.2f}\n"
            f"[–û–ø—ã—Ç –ò–ò: {self.knowledge.learning_rate:.1f}%]"
        )

    def generate_response(self, query: str, context: str = "") -> str:
        if not query:
            return "–û—à–∏–±–∫–∞: –ó–∞–ø—Ä–æ—Å –ø—É—Å—Ç"
        
        if "–∫–æ–¥" not in query.lower() and "code" not in query.lower() and not re.findall(r'https?://\S+', query):
            return self.suggest_action_algorithm(query)
        
        urls = re.findall(r'https?://\S+', query)
        if urls:
            success = self.knowledge.save_web_content(urls[0], query)
            return f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å {urls[0]}\n[–û–ø—ã—Ç –ò–ò: {self.knowledge.learning_rate:.1f}%]" if success else f"–û—à–∏–±–∫–∞ —Å {urls[0]}"
        
        if "–∫–æ–¥" in query.lower() or "code" in query.lower():
            try:
                formatted_code = black.format_str(query, mode=black.FileMode())
                purpose, location = self.code_optimizer.classify_code(query)
                errors = self.code_optimizer.detect_errors(query)
                response = f"–û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥:\n{formatted_code}\n\n–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:\n- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {purpose}\n- –ú–µ—Å—Ç–æ: {location}\n\n–û—à–∏–±–∫–∏:\n" + "\n".join(errors)
                self.knowledge.save(query, response)
                return f"{response}\n[–û–ø—ã—Ç –ò–ò: {self.knowledge.learning_rate:.1f}%]"
            except Exception as e:
                return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–¥–∞: {e}"
        
        built_context = self.knowledge.build_context(query)
        prompt = {
            "modelUri": f"gpt://{self.config.get_folder_id()}/{self.gpt.model}",
            "completionOptions": {
                "stream": False,
                "temperature": max(0.3, 0.6 - (self.knowledge.learning_rate / 200)),
                "maxTokens": 2000
            },
            "messages": [
                {
                    "role": "system",
                    "text": f"–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —É—á–∏—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞ (—Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å: {self.knowledge.learning_rate:.1f}%). –ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –¥–ª—è –ª–æ–≥–∏—á–µ—Å–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤."
                },
                {
                    "role": "user",
                    "text": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{built_context}\n\n–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å: {query}"
                }
            ]
        }
        response = self.gpt.invoke(prompt)
        resp_score = self.text_analyzer.predict_sentiment_score(response)
        logging.info(f"Fast.ai –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞: {response[:50]}... -> –æ—Ü–µ–Ω–∫–∞: {resp_score:.2f}")
        self.knowledge.save(query, response, context=built_context)
        return f"{response}\n\n–û—Ü–µ–Ω–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: {resp_score:.2f}\n[–û–ø—ã—Ç –ò–ò: {self.knowledge.learning_rate:.1f}%]"

class CodePasteWindow(ctk.CTkToplevel):
    def __init__(self, parent, callback):
        super().__init__(parent)
        self.title("–í—Å—Ç–∞–≤–∫–∞ –∫–æ–¥–∞")
        self.geometry("400x300")
        self.callback = callback
        self._init_ui()

    def _init_ui(self):
        self.code_entry = ctk.CTkTextbox(self, width=380, height=200, fg_color="#1C2526", text_color="#FFFFFF", font=("Courier", 12))
        self.code_entry.pack(padx=10, pady=10, fill="both", expand=True)
        self.code_entry.insert("1.0", "# –í—Å—Ç–∞–≤—å—Ç–µ –∫–æ–¥ –∑–¥–µ—Å—å\n")

        button_frame = ctk.CTkFrame(self, fg_color="#2F3536")
        button_frame.pack(fill="x", padx=10, pady=5)
        
        ctk.CTkButton(button_frame, text="–í—Å—Ç–∞–≤–∏—Ç—å", command=self._paste_code, fg_color="#1C2526", hover_color="#4A4A4A").pack(side="left", padx=5)
        ctk.CTkButton(button_frame, text="–£–≤–µ–ª–∏—á–∏—Ç—å", command=self._enlarge_window, fg_color="#1C2526", hover_color="#4A4A4A").pack(side="left", padx=5)
        ctk.CTkButton(button_frame, text="–£–º–µ–Ω—å—à–∏—Ç—å", command=self._shrink_window, fg_color="#1C2526", hover_color="#4A4A4A").pack(side="left", padx=5)
        ctk.CTkButton(button_frame, text="–û—Ç–º–µ–Ω–∞", command=self.destroy, fg_color="#1C2526", hover_color="#4A4A4A").pack(side="left", padx=5)

    def _paste_code(self):
        code = self.code_entry.get("1.0", "end-1c").strip()
        if code:
            self.callback(code)
        self.destroy()

    def _enlarge_window(self):
        current_width, current_height = map(int, self.geometry().split('x')[0:2])
        self.geometry(f"{current_width + 100}x{current_height + 100}")

    def _shrink_window(self):
        current_width, current_height = map(int, self.geometry().split('x')[0:2])
        if current_width > 200 and current_height > 200:
            self.geometry(f"{current_width - 100}x{current_height - 100}")

class NereMoreInterface(ctk.CTk):
    def __init__(self):
        logging.info("–®–∞–≥ 0: –ù–∞—á–∞–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ NereMoreInterface")
        try:
            super().__init__()
            self.title("Nere More")
            self.geometry("600x450")
            self.configure(fg_color="#1C2526")
            self.initialized = False

            self.audio = AudioManager()
            self.services = YandexAIServices(self)
            self.config = Config()
            self.context = deque(maxlen=self.config.data["ui"]["max_context"] * 2)
            self.interactive_behavior = InteractiveBehavior(self)

            self.logo_label = ctk.CTkLabel(self, text="Nere More", font=("Arial", 20, "bold"), text_color="#FFFFFF")
            self.logo_label.pack(pady=10)

            self.input_frame = ctk.CTkFrame(self, fg_color="#2F3536", corner_radius=10)
            self.input_frame.pack(fill="x", padx=10, pady=5)
            self.input_entry = ctk.CTkEntry(self.input_frame, width=350, height=40, font=("Arial", 14),
                                            placeholder_text="–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å...", fg_color="#1C2526", text_color="#FFFFFF")
            self.input_entry.pack(side="left", padx=10, pady=5)
            self.input_entry.bind("<Return>", lambda e: self.process_input_with_interaction())

            buttons = [
                ("üìã", lambda: CodePasteWindow(self, self._paste_text_callback), "–í—Å—Ç–∞–≤–∏—Ç—å"),
                ("üß≤", self._magnet_search, "–ü–æ–∏—Å–∫"),
                ("üîç", self.process_input, "–û–±—Ä–∞–±–æ—Ç–∞—Ç—å"),
                ("üåü", self.show_skills, "–£–º–µ–Ω–∏—è"),
                ("‚öôÔ∏è", lambda: APISettingsWindow(self, self.config), "–ù–∞—Å—Ç—Ä–æ–π–∫–∏"),
                ("üîë", lambda: APIKeyCheckWindow(self, self.services, self.config), "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞"),
                ("üíª", lambda: CodeEditorWindow(self, self.services), "–†–µ–¥–∞–∫—Ç–æ—Ä –∫–æ–¥–∞"),
                ("üìä", self.train_model, "–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"),
            ]
            for text, cmd, hover in buttons:
                btn = ctk.CTkButton(self.input_frame, text=text, width=40, height=40, fg_color="#1C2526", hover_color="#4A4A4A",
                                   text_color="#FFFFFF", command=cmd)
                btn.pack(side="left", padx=5)

            self.results_text = ctk.CTkTextbox(self, width=580, height=300, fg_color="#2F3536", text_color="#FFFFFF")
            self.results_text.pack(padx=10, pady=5)

            self.button_frame = ctk.CTkFrame(self, fg_color="#2F3536")
            self.button_frame.pack(fill="x", padx=10, pady=5)
            compact_buttons = [
                ("üìã", lambda: CodePasteWindow(self, self._paste_text_callback), "–í—Å—Ç–∞–≤–∏—Ç—å"),
                ("üß≤", self._magnet_search, "–ü–æ–∏—Å–∫"),
                ("üîç", self.process_input, "–û–±—Ä–∞–±–æ—Ç–∞—Ç—å"),
                ("üåü", self.show_skills, "–£–º–µ–Ω–∏—è"),
                ("‚öôÔ∏è", lambda: APISettingsWindow(self, self.config), "–ù–∞—Å—Ç—Ä–æ–π–∫–∏"),
                ("üîë", lambda: APIKeyCheckWindow(self, self.services, self.config), "–ü—Ä–æ–≤–µ—Ä–∫–∞"),
                ("üíª", lambda: CodeEditorWindow(self, self.services), "–†–µ–¥–∞–∫—Ç–æ—Ä"),
                ("üìä", self.train_model, "–û–±—É—á–∏—Ç—å"),
            ]
            for text, cmd, hover in compact_buttons:
                btn = ctk.CTkButton(self.button_frame, text=text, width=30, height=30, fg_color="#1C2526", hover_color="#4A4A4A",
                                   text_color="#FFFFFF", command=cmd)
                btn.pack(side="left", padx=2)

            self.status_label = ctk.CTkLabel(self, text="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...", font=("Arial", 10), text_color="#FFFFFF")
            self.status_label.pack(side="bottom", pady=2)

            available, status = self.services.check_api_key()
            self.status_label.configure(text=f"–°—Ç–∞—Ç—É—Å API: {status}")

            self.protocol("WM_DELETE_WINDOW", self._on_closing)
            self.initialized = True
            self.status_label.configure(text=f"–ì–æ—Ç–æ–≤ [–û–ø—ã—Ç –ò–ò: {self.services.knowledge.learning_rate:.1f}%]")
            self.interactive_behavior.start()
        except Exception as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}", exc_info=True)
            messagebox.showerror("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: {e}")
            self.destroy()

    def _on_closing(self):
        logging.info("–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
        self.interactive_behavior.stop()
        if pygame.mixer.get_init():
            pygame.mixer.quit()
        self.services.knowledge.db.close()
        self.destroy()

    def display_response(self, text: str):
        self.results_text.delete("1.0", "end")
        try:
            json_response = json.loads(text)
            self.results_text.insert("1.0", json.dumps(json_response, ensure_ascii=False, indent=2))
        except json.JSONDecodeError:
            self.results_text.insert("1.0", text)
        self.status_label.configure(text=f"–ì–æ—Ç–æ–≤ [–û–ø—ã—Ç –ò–ò: {self.services.knowledge.learning_rate:.1f}%]")

    def process_input(self):
        query = self.input_entry.get().strip()
        if not query:
            return
        self.input_entry.delete(0, "end")
        if query.lower().startswith("clear cache"):
            text_id = query.split("ID:")[-1].strip() if "ID:" in query else None
            self.services.knowledge._clear_cache(text_id)
            self.display_response(f"–ö—ç—à {'–¥–ª—è ID: ' + text_id if text_id else '–ø–æ–ª–Ω–æ—Å—Ç—å—é'} –æ—á–∏—â–µ–Ω")
        else:
            response = self.services.generate_response(query, self._get_context())
            self.display_response(response)
            self.context.append({"role": "user", "content": query})
            self.context.append({"role": "assistant", "content": response})

    def process_input_with_interaction(self):
        self.interactive_behavior.update_last_interaction()
        self.process_input()

    def train_model(self):
        response = self.services.train_and_visualize(epochs=50, batch_size=32, optimizer_name="Adam", learning_rate=0.001)
        self.display_response(response)

    def _paste_text_callback(self, content):
        if "def" in content or "class" in content:
            purpose, location = self.services.code_optimizer.classify_code(content)
            errors = self.services.code_optimizer.detect_errors(content)
            formatted_code = black.format_str(content, mode=black.FileMode()) if not errors else content
            response = f"–ö–æ–¥ –≤—Å—Ç–∞–≤–ª–µ–Ω:\n{formatted_code}\n\n–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:\n- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {purpose}\n- –ú–µ—Å—Ç–æ: {location}\n\n–û—à–∏–±–∫–∏:\n" + "\n".join(errors)
            self.services.knowledge.save(f"Inserted code (ID: {uuid.uuid4().hex[:8]})", formatted_code)
            self.display_response(response)
        else:
            self.services.knowledge.save(f"Inserted text (ID: {uuid.uuid4().hex[:8]})", content)
            self.display_response(f"–í—Å—Ç–∞–≤–ª–µ–Ω–æ: {content[:100]}...")

    def _magnet_search(self):
        query = self.input_entry.get().strip()
        if query:
            similar = self.services.knowledge.get_similar(query)
            self.display_response("\n".join(f"[{s:.2f}] {q}: {r}" for q, r, s in similar) or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

    def show_skills(self):
        self.display_response(f"–£–º–µ–Ω–∏—è:\n- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º —ç–º–æ—Ü–∏–π\n- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–¥–∞\n- –†–∞–±–æ—Ç–∞ —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Ä–µ—Å—É—Ä—Å–∞–º–∏\n- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\n- –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞\n- –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã\n- –ò–Ω—Å–ø–µ–∫—Ü–∏—è –∫–æ–¥–∞\n- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n\n–¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å –æ–ø—ã—Ç–∞: {self.services.knowledge.learning_rate:.1f}%")

    def _get_context(self) -> str:
        return "\n".join(f"{msg['role']}: {msg['content']}" for msg in self.context)

    def run(self):
        if self.initialized:
            logging.info("–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
            self.mainloop()
        else:
            logging.error("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ, –∑–∞–ø—É—Å–∫ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω")

class APISettingsWindow(ctk.CTkToplevel):
    def __init__(self, parent, config):
        super().__init__(parent)
        self.title("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ API")
        self.geometry("300x250")
        self.config = config
        self._init_ui()

    def _init_ui(self):
        ctk.CTkLabel(self, text="YandexGPT key:").grid(row=0, column=0, padx=5, pady=5)
        self.key_entry = ctk.CTkEntry(self, width=150)
        self.key_entry.grid(row=0, column=1, padx=5, pady=5)
        self.key_entry.insert(0, self.config.get_key())

        ctk.CTkButton(self, text="üìã –í—Å—Ç–∞–≤–∏—Ç—å", command=self._paste_key,
                     width=80, fg_color="#1C2526", hover_color="#4A4A4A").grid(row=0, column=2, padx=5)

        ctk.CTkLabel(self, text="Folder ID:").grid(row=1, column=0, padx=5, pady=5)
        self.folder_entry = ctk.CTkEntry(self, width=150)
        self.folder_entry.grid(row=1, column=1, padx=5, pady=5)
        self.folder_entry.insert(0, self.config.get_folder_id())

        ctk.CTkButton(self, text="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å", command=self._save_api_key,
                     fg_color="#1C2526", hover_color="#4A4A4A").grid(row=2, column=0, columnspan=3, pady=10)

        self.status_label = ctk.CTkLabel(self, text="")
        self.status_label.grid(row=3, column=0, columnspan=3, pady=5)

    def _paste_key(self):
        try:
            clipboard_text = self.clipboard_get()
            if clipboard_text:
                self.key_entry.delete(0, "end")
                self.key_entry.insert(0, clipboard_text)
                self.status_label.configure(text="–¢–µ–∫—Å—Ç –≤—Å—Ç–∞–≤–ª–µ–Ω –∏–∑ –±—É—Ñ–µ—Ä–∞")
            else:
                self.status_label.configure(text="–ë—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞ –ø—É—Å—Ç")
        except tk.TclError:
            self.status_label.configure(text="–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –±—É—Ñ–µ—Ä—É")

    def _save_api_key(self):
        key = self.key_entry.get().strip()
        folder_id = self.folder_entry.get().strip()

        if not key or not folder_id:
            self.status_label.configure(text="–û—à–∏–±–∫–∞: –ü–æ–ª—è –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º–∏")
            return

        if not validate_folder_id(folder_id):
            self.status_label.configure(text="–û—à–∏–±–∫–∞: folder_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 20 —Å–∏–º–≤–æ–ª–æ–≤ (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã)")
            return

        temp_gpt = YandexGPT(key, folder_id)
        is_valid, status_message = temp_gpt.check_availability()
        self.status_label.configure(text=status_message)

        if is_valid:
            self.config.update_api_key("gpt_key_1", key)
            self.config.update_folder_id(folder_id)
            self.status_label.configure(text="–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            self.after(1000, self.destroy)

class APIKeyCheckWindow(ctk.CTkToplevel):
    def __init__(self, parent, services, config):
        super().__init__(parent)
        self.title("–ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞")
        self.geometry("400x300")
        self.services = services
        self.config = config
        self._init_ui()

    def _init_ui(self):
        ctk.CTkLabel(self, text="–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á:").grid(row=0, column=0, padx=5, pady=5)
        self.key_entry = ctk.CTkEntry(self, width=200)
        self.key_entry.grid(row=0, column=1)
        ctk.CTkLabel(self, text="Folder ID:").grid(row=1, column=0, padx=5, pady=5)
        self.folder_entry = ctk.CTkEntry(self, width=200)
        self.folder_entry.grid(row=1, column=1)
        self.folder_entry.insert(0, self.config.get_folder_id())
        ctk.CTkButton(self, text="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å", command=self._check_key).grid(row=2, column=0, columnspan=2, pady=10)
        self.status_text = ctk.CTkTextbox(self, width=350, height=100)
        self.status_text.grid(row=3, column=0, columnspan=2)

    def _check_key(self):
        key = self.key_entry.get()
        folder_id = self.folder_entry.get()
        if key and validate_folder_id(folder_id):
            gpt = YandexGPT(key, folder_id)
            available, status = gpt.check_availability()
            self.status_text.delete("1.0", "end")
            self.status_text.insert("1.0", f"–°—Ç–∞—Ç—É—Å: {status}")

if __name__ == "__main__":
    try:
        nltk.download('vader_lexicon', quiet=True)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ nltk –¥–∞–Ω–Ω—ã—Ö: {e}")
    app = NereMoreInterface()
    app.run()